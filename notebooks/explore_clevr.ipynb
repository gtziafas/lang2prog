{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/p300488/lang2prog\n"
     ]
    }
   ],
   "source": [
    " cd /data/p300488/lang2prog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring CLEVR questions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = '/data/p300488/lang2prog'\n",
    "clevr_path = '/data/p300488/datasets/clevr/CLEVR_v1.0'\n",
    "train_questions_path = os.path.join(clevr_path, 'questions/CLEVR_train_questions.json')\n",
    "val_questions_path = os.path.join(clevr_path, 'questions/CLEVR_val_questions.json')\n",
    "test_questions_path = os.path.join(clevr_path, 'questions/CLEVR_test_questions.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read GQA questions dataset. Size of training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699989\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "ds = json.load(open(train_questions_path))['questions']\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the structure of a sample, it contains a program annotation for the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'yes',\n",
      " 'image_filename': 'CLEVR_train_000000.png',\n",
      " 'image_index': 0,\n",
      " 'program': [{'function': 'scene', 'inputs': [], 'value_inputs': []},\n",
      "             {'function': 'filter_size',\n",
      "              'inputs': [0],\n",
      "              'value_inputs': ['large']},\n",
      "             {'function': 'filter_color',\n",
      "              'inputs': [1],\n",
      "              'value_inputs': ['green']},\n",
      "             {'function': 'count', 'inputs': [2], 'value_inputs': []},\n",
      "             {'function': 'scene', 'inputs': [], 'value_inputs': []},\n",
      "             {'function': 'filter_size',\n",
      "              'inputs': [4],\n",
      "              'value_inputs': ['large']},\n",
      "             {'function': 'filter_color',\n",
      "              'inputs': [5],\n",
      "              'value_inputs': ['purple']},\n",
      "             {'function': 'filter_material',\n",
      "              'inputs': [6],\n",
      "              'value_inputs': ['metal']},\n",
      "             {'function': 'filter_shape',\n",
      "              'inputs': [7],\n",
      "              'value_inputs': ['cube']},\n",
      "             {'function': 'count', 'inputs': [8], 'value_inputs': []},\n",
      "             {'function': 'greater_than',\n",
      "              'inputs': [3, 9],\n",
      "              'value_inputs': []}],\n",
      " 'question': 'Are there more big green things than large purple shiny cubes?',\n",
      " 'question_family_index': 2,\n",
      " 'question_index': 0,\n",
      " 'split': 'train'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let'see all the different reasoning primitives and their related concept values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count',\n",
      " 'equal_color',\n",
      " 'equal_integer',\n",
      " 'equal_material',\n",
      " 'equal_shape',\n",
      " 'equal_size',\n",
      " 'exist',\n",
      " 'filter_color[blue]',\n",
      " 'filter_color[brown]',\n",
      " 'filter_color[cyan]',\n",
      " 'filter_color[gray]',\n",
      " 'filter_color[green]',\n",
      " 'filter_color[purple]',\n",
      " 'filter_color[red]',\n",
      " 'filter_color[yellow]',\n",
      " 'filter_material[metal]',\n",
      " 'filter_material[rubber]',\n",
      " 'filter_shape[cube]',\n",
      " 'filter_shape[cylinder]',\n",
      " 'filter_shape[sphere]',\n",
      " 'filter_size[large]',\n",
      " 'filter_size[small]',\n",
      " 'greater_than',\n",
      " 'intersect',\n",
      " 'less_than',\n",
      " 'query_color',\n",
      " 'query_material',\n",
      " 'query_shape',\n",
      " 'query_size',\n",
      " 'relate[behind]',\n",
      " 'relate[front]',\n",
      " 'relate[left]',\n",
      " 'relate[right]',\n",
      " 'same_color',\n",
      " 'same_material',\n",
      " 'same_shape',\n",
      " 'same_size',\n",
      " 'scene',\n",
      " 'union',\n",
      " 'unique'}\n"
     ]
    }
   ],
   "source": [
    "all_primitives = set()\n",
    "for sample in ds:\n",
    "    for node in sample['program']:\n",
    "        _fn = node['function']\n",
    "        _side_input =  '[' + node['value_inputs'][0] + ']' if node['value_inputs'] else ''\n",
    "        all_primitives.add(_fn + _side_input)\n",
    "\n",
    "pprint(all_primitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this formalism, the primitives are both concept-aware (``filter_color, filter_size`` etc.), as well as vocabulary-aware (``filter_color[red], filter_color[blue]``, etc ). Let's create a version which decouples specific concept values from the primitives (*vocabulary-agnostic*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count',\n",
      " 'equal_color',\n",
      " 'equal_integer',\n",
      " 'equal_material',\n",
      " 'equal_shape',\n",
      " 'equal_size',\n",
      " 'exist',\n",
      " 'filter_color',\n",
      " 'filter_material',\n",
      " 'filter_shape',\n",
      " 'filter_size',\n",
      " 'greater_than',\n",
      " 'intersect',\n",
      " 'less_than',\n",
      " 'query_color',\n",
      " 'query_material',\n",
      " 'query_shape',\n",
      " 'query_size',\n",
      " 'relate',\n",
      " 'same_color',\n",
      " 'same_material',\n",
      " 'same_shape',\n",
      " 'same_size',\n",
      " 'scene',\n",
      " 'union',\n",
      " 'unique'}\n"
     ]
    }
   ],
   "source": [
    "vocab_agnostic_primitives = set()\n",
    "concept_agnostic_primitives = set()\n",
    "for fn in all_primitives:\n",
    "    f = fn.split('[')[0]\n",
    "    vocab_agnostic_primitives.add(f)\n",
    "    if len(f.split('_')) > 1:\n",
    "        f = f.split('_')[0] if f.split('_')[1] not in ['than', 'integer'] else f\n",
    "    concept_agnostic_primitives.add(f)\n",
    "\n",
    "pprint(vocab_agnostic_primitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the most general formalism, without concept-awareness (*concept_agnostic*)\\:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count',\n",
      " 'equal',\n",
      " 'equal_integer',\n",
      " 'exist',\n",
      " 'filter',\n",
      " 'greater_than',\n",
      " 'intersect',\n",
      " 'less_than',\n",
      " 'query',\n",
      " 'relate',\n",
      " 'same',\n",
      " 'scene',\n",
      " 'union',\n",
      " 'unique'}\n"
     ]
    }
   ],
   "source": [
    "pprint(concept_agnostic_primitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give some context on different primitive types:\n",
    "\n",
    "   - **Operational** : ``scene``: Initializes a set of objects given RGB image, ``unique``: {n} -> n\n",
    "   \n",
    "   - **Logical**: ``union/intersection``: union / intersection of two sets (outputs of two reasoning branches),\n",
    "   \n",
    "   - **Enumeration**: ``exist``: is a set non-empty?, ``count``: size of set, ``less_than/greater_than/equal_integer``: compares two integers\n",
    "   \n",
    "   - **Visual**: ``filter``: isolate object set based on attribute value, ``query``: ask for an attribute value, ``same``: object set which has same attribute value as given, ``equal``: whether two objects have equal attribute value\n",
    "   \n",
    "   - **Spatial**: ``relate``: object set which has certain spatial relation to given object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Language-to-Program datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the program annotations to a universal format, which also works for GQA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ProgramNode:\n",
    "    step: int\n",
    "    function: str\n",
    "    value_input: Optional[str]\n",
    "    inputs: Sequence[int]\n",
    "    _outputs: Optional[Sequence[int]] = field(default=None)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({str(self.step)}): {self.function}{'['+self.value_input+']' if self.value_input is not None else ''}({','.join(list(map(str, self.inputs))) if self.inputs else ''})\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formalize_program_annots(ds):\n",
    "    programs = []\n",
    "    for sample in ds:\n",
    "        _nodes = []\n",
    "        for i, node in enumerate(sample['program']):\n",
    "            _value = None if not node['value_inputs'] else node['value_inputs'][0]\n",
    "            _nodes.append(ProgramNode(step=i,\n",
    "                                     function=node['function'],\n",
    "                                     inputs=node['inputs'],\n",
    "                                     value_input=_value,\n",
    "            ))\n",
    "        programs.append(_nodes)\n",
    "    return programs\n",
    "\n",
    "\n",
    "# do for training set\n",
    "train_progs = formalize_program_annots(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some processed program annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0): scene(),\n",
      "  (1): filter_size[large](0),\n",
      "  (2): filter_color[green](1),\n",
      "  (3): count(2),\n",
      "  (4): scene(),\n",
      "  (5): filter_size[large](4),\n",
      "  (6): filter_color[purple](5),\n",
      "  (7): filter_material[metal](6),\n",
      "  (8): filter_shape[cube](7),\n",
      "  (9): count(8),\n",
      "  (10): greater_than(3,9)],\n",
      " [(0): scene(),\n",
      "  (1): filter_size[small](0),\n",
      "  (2): filter_color[cyan](1),\n",
      "  (3): filter_material[rubber](2),\n",
      "  (4): unique(3),\n",
      "  (5): same_shape(4),\n",
      "  (6): count(5)],\n",
      " [(0): scene(),\n",
      "  (1): filter_size[large](0),\n",
      "  (2): filter_shape[sphere](1),\n",
      "  (3): unique(2),\n",
      "  (4): scene(),\n",
      "  (5): filter_size[large](4),\n",
      "  (6): filter_material[rubber](5),\n",
      "  (7): filter_shape[cube](6),\n",
      "  (8): unique(7),\n",
      "  (9): query_color(3),\n",
      "  (10): query_color(8),\n",
      "  (11): equal_color(9,10)],\n",
      " [(0): scene(),\n",
      "  (1): filter_size[large](0),\n",
      "  (2): filter_color[brown](1),\n",
      "  (3): filter_shape[sphere](2),\n",
      "  (4): unique(3),\n",
      "  (5): relate[left](4),\n",
      "  (6): scene(),\n",
      "  (7): filter_color[brown](6),\n",
      "  (8): filter_shape[cylinder](7),\n",
      "  (9): unique(8),\n",
      "  (10): relate[right](9),\n",
      "  (11): intersect(5,10),\n",
      "  (12): filter_size[large](11),\n",
      "  (13): unique(12),\n",
      "  (14): query_material(13)],\n",
      " [(0): scene(),\n",
      "  (1): filter_color[brown](0),\n",
      "  (2): filter_material[metal](1),\n",
      "  (3): filter_shape[sphere](2),\n",
      "  (4): unique(3),\n",
      "  (5): query_size(4)]]\n"
     ]
    }
   ],
   "source": [
    "pprint(train_progs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for val and test datasets as well and save them under ``checkpoints`` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'program'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-26bee92a763f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0m_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_questions_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0m_progs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformalize_program_annots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CLEVR_test_programs.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_progs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-faeaab969ebc>\u001b[0m in \u001b[0;36mformalize_program_annots\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0m_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'program'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value_inputs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value_inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             _nodes.append(ProgramNode(step=i,\n",
      "\u001b[0;31mKeyError\u001b[0m: 'program'"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(root, \"checkpoints/clevr_programs\")\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "with open(os.path.join(save_dir, 'CLEVR_train_programs.json'), 'w') as f:\n",
    "    json.dump([[p.__dict__ for p in ps] for ps in train_progs], f)\n",
    "    \n",
    "_ds = json.load(open(val_questions_path))['questions']\n",
    "_progs = formalize_program_annots(_ds)\n",
    "with open(os.path.join(save_dir, 'CLEVR_val_programs.json'), 'w') as f:\n",
    "    json.dump([[p.__dict__ for p in ps] for ps in _progs], f)\n",
    "\n",
    "_ds = json.load(open(test_questions_path))['questions']\n",
    "_progs = formalize_program_annots(_ds)\n",
    "with open(os.path.join(save_dir, 'CLEVR_test_programs.json'), 'w') as f:\n",
    "    json.dump([[p.__dict__ for p in ps] for ps in _progs], f)\n",
    "\n",
    "del _ds, _progs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
